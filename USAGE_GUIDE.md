# Quick Start Guide - CodeT5 Docstring Generator

## ğŸ“‹ Table of Contents
1. [Installation](#installation)
2. [Testing Your Setup](#testing-your-setup)
3. [Training the Model](#training-the-model)
4. [Using the Model](#using-the-model)
5. [API Deployment](#api-deployment)
6. [Troubleshooting](#troubleshooting)

---

## ğŸš€ Installation

### Step 1: Clone/Download the Project
```bash
cd your-project-directory
```

### Step 2: Create Virtual Environment
```bash
# Create virtual environment
python -m venv venv

# Activate (Linux/Mac)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Testing Your Setup

### Quick System Test
```bash
python test_system.py
```

This will check:
- âœ… Python version
- âœ… All dependencies
- âœ… GPU/CUDA availability
- âœ… System resources
- âœ… HuggingFace access

### Quick CUDA Test Only
```bash
python test_system.py --quick
```

### Auto-Install Missing Packages
```bash
python test_system.py --install
```

---

## ğŸ¯ Training the Model

### Option 1: Default Training (Recommended for RTX 3080)
```bash
python codet5_docstring_generator.py
```

**Expected Output:**
```
ğŸ”¥ GPU Detection:
   â”œâ”€ Number of GPUs available: 1
   â”œâ”€ GPU 0: NVIDIA GeForce RTX 3080 (10.00 GB)
   â””â”€ Single GPU training on NVIDIA GeForce RTX 3080

ğŸ“¦ Loading dataset...
ğŸ”§ Preprocessing training data...
   â”œâ”€ Training samples: 251,820
   â””â”€ Validation samples: 13,914

ğŸ¤– Loading CodeT5 model...
   â””â”€ Model loaded: Salesforce/codet5-base
   â””â”€ Total parameters: 220.00M

ğŸš€ Starting training...
   â”œâ”€ Epochs: 10
   â”œâ”€ Batch size per device: 8
   â”œâ”€ Effective batch size: 16
   â””â”€ Total training steps: 157,387
```

### Option 2: Custom Training Configuration

#### Quick Test (for debugging)
```python
from config import get_config, print_config
from codet5_docstring_generator import CodeT5DocstringGenerator

# Load quick test config
config = get_config("quick_test")
print_config(config)

# Train with config
generator = CodeT5DocstringGenerator(
    model_name=config.model.model_name
)
# ... continue with custom parameters
```

#### Multi-GPU Training
```python
# Automatically detected if you have multiple GPUs
# No code changes needed!
```

---

## ğŸ’¡ Using the Model

### Method 1: Python Script
```python
from codet5_docstring_generator import CodeT5DocstringGenerator

# Initialize
generator = CodeT5DocstringGenerator()
generator.setup_model()

# Your code
code = """
def factorial(n):
    if n <= 1:
        return 1
    return n * factorial(n-1)
"""

# Generate docstring
docstring = generator.generate_docstring(code)
print(f'"""{docstring}"""')
```

### Method 2: Interactive Demo
```bash
python demo.py
```

**Menu Options:**
1. Run Example Generations
2. Interactive Mode (Enter Custom Code)
3. Exit

**Interactive Mode Example:**
```
>>> def my_function(x, y):
...     return x + y
... END

âœ¨ Generated Docstring:
"""Add two values and return their sum."""
```

---

## ğŸŒ API Deployment

### Start the API Server
```bash
python api_server.py
```

**Server Info:**
```
ğŸš€ Server starting...
   â”œâ”€ Model: ./codet5-docstring-model
   â”œâ”€ Device: cuda
   â””â”€ Endpoints:
      â”œâ”€ GET  /health   - Health check
      â”œâ”€ POST /generate - Generate docstring
      â”œâ”€ POST /batch    - Batch generation
      â””â”€ GET  /example  - Usage example

ğŸ“¡ Server will run on http://0.0.0.0:5000
```

### API Usage Examples

#### Health Check
```bash
curl http://localhost:5000/health
```

#### Generate Docstring
```bash
curl -X POST http://localhost:5000/generate \
  -H "Content-Type: application/json" \
  -d '{
    "code": "def add(a, b):\n    return a + b",
    "max_length": 150,
    "num_beams": 5,
    "temperature": 0.7
  }'
```

**Response:**
```json
{
    "success": true,
    "docstring": "Add two numbers and return the result.",
    "inference_time": "0.245s",
    "model": "./codet5-docstring-model"
}
```

#### Batch Generation
```bash
curl -X POST http://localhost:5000/batch \
  -H "Content-Type: application/json" \
  -d '{
    "codes": [
      "def func1():\n    pass",
      "def func2():\n    pass"
    ]
  }'
```

---

## ğŸ“Š Evaluation

### Evaluate Trained Model
```bash
python evaluate_model.py
```

**Expected Output:**
```
ğŸ“Š BLEU Scores:
   â”œâ”€ BLEU: 42.5000
   â”œâ”€ BLEU-1: 58.3000
   â”œâ”€ BLEU-2: 45.2000
   â”œâ”€ BLEU-3: 38.7000
   â””â”€ BLEU-4: 32.1000

ğŸ“Š ROUGE Scores:
   â”œâ”€ ROUGE-1: 0.5830
   â”œâ”€ ROUGE-2: 0.3870
   â””â”€ ROUGE-L: 0.5420

ğŸ“Š Additional Metrics:
   â”œâ”€ Exact Match: 15.80%
   â””â”€ Samples Evaluated: 1000
```

---

## ğŸ”§ Troubleshooting

### Problem: CUDA Out of Memory

**Solution 1: Reduce Batch Size**
```python
# In codet5_docstring_generator.py
batch_size=4  # Instead of 8
```

**Solution 2: Enable Gradient Checkpointing** (Already enabled)
```python
gradient_checkpointing=True
```

**Solution 3: Reduce Sequence Length**
```python
max_length=256  # Instead of 512
```

### Problem: Slow Training

**Check GPU Usage:**
```bash
nvidia-smi
# Should show ~90%+ GPU utilization
```

**Solutions:**
- âœ… Mixed precision is already enabled (FP16)
- âœ… Increase batch size if GPU has headroom
- âœ… Ensure dataloader workers are set correctly

### Problem: Import Errors

**Solution:**
```bash
# Reinstall transformers
pip uninstall transformers
pip install transformers==4.35.0

# Or reinstall all
pip install -r requirements.txt --force-reinstall
```

### Problem: Model Not Found

**Solution:**
```bash
# Make sure you've trained the model first
python codet5_docstring_generator.py

# Or check the model path
ls -la ./codet5-docstring-model/
```

---

## ğŸ“ˆ Performance Tips

### For RTX 3080 (10GB VRAM)
- âœ… Batch size: 8
- âœ… FP16 enabled
- âœ… Gradient accumulation: 2
- âœ… Gradient checkpointing: True

### For Multi-GPU Setup
- âœ… Automatic detection
- âœ… DataParallel wrapping
- âœ… Effective batch size multiplied

### For CPU Training
- âš ï¸ Disable FP16
- âš ï¸ Reduce batch size to 2-4
- âš ï¸ Expect 10-20x slower training

---

## ğŸ“š File Structure

```
codet5-docstring-generator/
â”œâ”€â”€ codet5_docstring_generator.py  # Main training script â­
â”œâ”€â”€ evaluate_model.py               # Evaluation metrics
â”œâ”€â”€ api_server.py                   # REST API server
â”œâ”€â”€ demo.py                         # Interactive demo
â”œâ”€â”€ config.py                       # Configuration management
â”œâ”€â”€ data_utils.py                   # Data preprocessing
â”œâ”€â”€ test_system.py                  # System verification
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ README.md                       # Full documentation
â””â”€â”€ USAGE_GUIDE.md                 # This file
```

---

## ğŸ“ Next Steps

1. âœ… **Test Your Setup**: `python test_system.py`
2. âœ… **Train the Model**: `python codet5_docstring_generator.py`
3. âœ… **Try the Demo**: `python demo.py`
4. âœ… **Evaluate Results**: `python evaluate_model.py`
5. âœ… **Deploy API**: `python api_server.py`

---

## ğŸ’¡ Tips for Portfolio

- ğŸ“¸ Take screenshots of training progress
- ğŸ“Š Include evaluation metrics in your presentation
- ğŸ¥ Record a demo video showing inference
- ğŸ“ Document any modifications you made
- ğŸ”¬ Add your own experiments/improvements

---

## ğŸ“§ Support

If you encounter issues:
1. Check the troubleshooting section above
2. Run `python test_system.py` for diagnostics
3. Review the full README.md
4. Check HuggingFace documentation

---

**Good luck with your portfolio project! ğŸš€**
